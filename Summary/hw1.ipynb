{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "with open('./data/train.jsonl', 'r') as f:\n",
    "    file = list(f)\n",
    "for row in file:\n",
    "    train.append(json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = {}\n",
    "# dictionary_rev = {}\n",
    "# for row in train:\n",
    "#     tokens = nlp(row['text'])\n",
    "#     tokens = [token for token in tokens if token.is_alpha]\n",
    "#     for tk in tokens:\n",
    "#         if not dictionary.get(tk):\n",
    "#             dictionary[tk] = len(dictionary)\n",
    "#             dictionary_rev[len(dictionary)] = tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1000000',\n",
       " 'summary': 'A seven-hundred-year old oak gate at Salisbury Cathedral has been demolished by a drink driver.\\n',\n",
       " 'text': 'The Grade I listed Harnham Gate was hit by a white van that smashed into the structure at about 02:00 BST.\\nA 51-year-old man, from West Dean, has been arrested on suspicion of failing to stop, criminal damage and driving with excess alcohol, police said.\\nWiltshire Police said the man remains in police custody and they have asked for witnesses to contact them.\\n',\n",
       " 'sent_bounds': [[0, 107], [107, 255], [255, 362]],\n",
       " 'extractive_summary': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"./glove.6B/glove.6B.300d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, w2v, test = False):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.w2v = w2v\n",
    "        self.test = test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        embedding, words = self.tokenize(self.data[idx])\n",
    "        embedding = torch.tensor(embedding)\n",
    "        _, y_words = self.tokenize(self.data[idx], ans = True)\n",
    "        \n",
    "        if not self.test:\n",
    "            return embedding, words, y_words\n",
    "        else:\n",
    "            return embedding\n",
    "    \n",
    "    def tokenize(self, sentence, ans = False):\n",
    "        if ans :\n",
    "            data = sentence['summary']\n",
    "        else:\n",
    "            data = sentence['text']\n",
    "        embedding = []\n",
    "        words = []\n",
    "        tokens = self.tokenizer(data)\n",
    "        \n",
    "        tokens = filter(lambda x : x.text.lower() in self.w2v.keys(), tokens)\n",
    "        for token in tokens:\n",
    "            if token.is_alpha:\n",
    "                token = token.lower_\n",
    "                embedding.append(self.w2v[token])\n",
    "                words.append(token)\n",
    "        return embedding, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    # 測試集有 labels\n",
    "    tokens_tensors, words, y_words = zip(*samples)\n",
    "    # zero pad 到同一序列長度\n",
    "    try:\n",
    "        tokens_tensors = pad_sequence(tokens_tensors, batch_first=True)\n",
    "    except :\n",
    "        return None, None, None\n",
    "    return tokens_tensors, words, y_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 300\n",
    "batch_size = 2\n",
    "nlp = en_core_web_sm.load()\n",
    "train_dataset = SummaryDataset(train, nlp, embeddings_dict)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, collate_fn=create_mini_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['a', 'seven', 'hundred', 'year', 'old', 'oak', 'gate', 'at', 'salisbury', 'cathedral', 'has', 'been', 'demolished', 'by', 'a', 'drink', 'driver'], ['the', 'parents', 'and', 'sister', 'of', 'the', 'late', 'mp', 'jo', 'cox', 'have', 'opened', 'a', 'new', 'birth', 'centre', 'at', 'a', 'hospital', 'in', 'her', 'constituency'])\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_model(input_size)\n",
    "for x,words, y_words in train_loader:\n",
    "\n",
    "#     pred = model(x)\n",
    "    print(y_words)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size =100, n_layers = 1, drop_prob=0.2, bidirectional = False):\n",
    "        super(LSTM_model, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.model = nn.LSTM(input_size, hidden_size, n_layers,  batch_first = True, bidirectional= bidirectional)\n",
    "        self.relu = nn.ReLU()\n",
    "        if bidirectional:\n",
    "            self.linear = nn.Linear(hidden_size * 2, 2) # input dim is 64*2 because its bidirectional\n",
    "        else:\n",
    "            self.linear = nn.Linear(hidden_size, 2)\n",
    "        self.init_hidden()\n",
    "        \n",
    "    def forward(self, x, h= None):\n",
    "\n",
    "        x, (hn, cn) = self.model(x, h)\n",
    "        output = self.relu(x)\n",
    "        output = self.linear(x)\n",
    "        return output[0]\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        for name, p in self.model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.orthogonal_(p)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(p, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peter",
   "language": "python",
   "name": "peter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
